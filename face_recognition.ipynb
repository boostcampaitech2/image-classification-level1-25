{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "source": [
                "import torch\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "from facenet_pytorch import MTCNN\n",
                "import os, cv2\n",
                "import albumentations as A"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
                "mtcnn = MTCNN(keep_all=True, device=device)\n",
                "new_img_dir = '/opt/ml/input/data/train/new_imgs'\n",
                "img_path = '/opt/ml/input/data/train/images'\n",
                "if not os.path.exists(new_img_dir):\n",
                "            os.makedirs(new_img_dir)\n",
                "\n",
                "cnt = 0\n",
                "detected = 0\n",
                "\n",
                "for paths in os.listdir(img_path):\n",
                "    if paths[0] == '.': continue\n",
                "    \n",
                "    sub_dir = os.path.join(img_path, paths)\n",
                "\n",
                "    for imgs in os.listdir(sub_dir):\n",
                "\n",
                "        if imgs[0] == '.': continue\n",
                "        \n",
                "        img_dir = os.path.join(sub_dir, imgs)\n",
                "        img = cv2.imread(img_dir)\n",
                "        img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
                "        \n",
                "        #mtcnn 적용\n",
                "        boxes,probs = mtcnn.detect(img)\n",
                "        if len(probs) > 1: \n",
                "            detected += 1\n",
                "            #print(boxes)\n",
                "        # no face found\n",
                "        if not isinstance(boxes, np.ndarray):\n",
                "            # 직접 crop\n",
                "            #img=img[100:400, 50:350, :]\n",
                "            img = A.CenterCrop(height = 384, width = 384)(image = img)['image']\n",
                "\n",
                "        # boexes size 확인\n",
                "        else:\n",
                "            xmin = int(boxes[0, 0])-30\n",
                "            ymin = int(boxes[0, 1])-30\n",
                "            xmax = int(boxes[0, 2])+30\n",
                "            ymax = int(boxes[0, 3])+30\n",
                "            \n",
                "            if xmin < 0: xmin = 0\n",
                "            if ymin < 0: ymin = 0\n",
                "            if xmax > 384: xmax = 384\n",
                "            if ymax > 512: ymax = 512\n",
                "            \n",
                "            img = img[ymin:ymax, xmin:xmax, :]\n",
                "            \n",
                "        tmp = os.path.join(new_img_dir, paths)\n",
                "        if not os.path.exists(tmp):\n",
                "            os.makedirs(tmp)\n",
                "\n",
                "        file_name = os.path.join(tmp,imgs)\n",
                "        #print(file_name)\n",
                "        \n",
                "        plt.imsave(file_name, img)\n",
                "        cnt += 1\n",
                "        print(detected, cnt)\n",
                "\n",
                "#668 18900"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "import cv2\n",
                "\n",
                "src = cv2.imread('/opt/ml/input/data/train/images/000001_female_Asian_45/normal.jpg')\n",
                "classifier = cv2.CascadeClassifier('haarcascade_frontalface_alt2.xml')\n",
                "\n",
                "faces = classifier.detectMultiScale(src) # 스케일팩터를 1.2로 지정해도 잘 작동함 더 빨라짐\n",
                "\n",
                "# 각각의 행마다 (x,y,w,h) 받아와서 사각형을 그리는 코드\n",
                "#for (x, y, w, h) in faces:\n",
                "#    cv2.rectangle(src, (x, y, w, h), (255, 0, 255), 2)\n",
                "\n",
                "print(faces)\n",
                "\n",
                "for (x,y,w,h) in faces:\n",
                "    cv2.rectangle(src, (x, y, w, h), (255, 0, 255), 2)\n",
                "cv2.imshow('src', src)\n",
                "cv2.waitKey()\n",
                "cv2.destroyAllWindows()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "import cv2\n",
                "\n",
                "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
                "new_img_dir = '/opt/ml/input/data/train/new_imgs'\n",
                "img_path = '/opt/ml/input/data/train/images'\n",
                "if not os.path.exists(new_img_dir):\n",
                "            os.makedirs(new_img_dir)\n",
                "\n",
                "cnt = 0\n",
                "detected = 0\n",
                "classifier = cv2.CascadeClassifier('haarcascade_frontalface_alt2.xml')\n",
                "\n",
                "for paths in os.listdir(img_path):\n",
                "    if paths[0] == '.': continue\n",
                "    \n",
                "    sub_dir = os.path.join(img_path, paths)\n",
                "\n",
                "    for imgs in os.listdir(sub_dir):\n",
                "\n",
                "        if imgs[0] == '.': continue\n",
                "        \n",
                "        img_dir = os.path.join(sub_dir, imgs)\n",
                "        img = cv2.imread(img_dir)\n",
                "        img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
                "        \n",
                "        \n",
                "        #mtcnn 적용\n",
                "        faces = classifier.detectMultiScale(img)\n",
                "        if len(faces)>=1: \n",
                "            detected += 1\n",
                "         \n",
                "        cnt += 1\n",
                "        print(detected, cnt)"
            ],
            "outputs": [],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.8.5",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.8.5 64-bit ('base': conda)"
        },
        "interpreter": {
            "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}