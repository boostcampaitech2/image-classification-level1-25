{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from pytz import timezone\n",
    "import datetime as dt\n",
    "\n",
    "from f1_score import f1_loss\n",
    "\n",
    "import wandb"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from models.model_bj import resnetbase3 as MaskModel\n",
    "from datasets.dataset_kj import MaskDatasetA as MaskDataset\n",
    "from trans.trans_bj import A_simple_trans as TrainTrans\n",
    "from trans.trans_bj import A_just_tensor as TestTrans\n",
    "\n",
    "CLASS_NUM = 18\n",
    "NUM_WORKERS = 4\n",
    "BATCH_SIZE = 16\n",
    "NUM_EPOCH = 20\n",
    "SAVE_INTERVAL = 3\n",
    "\n",
    "\n",
    "\n",
    "# wandb_name = 'RN18_BS16_TRbl'\n",
    "\n",
    "load_path = ''\n",
    "\n",
    "comment = ''"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "c = ''\n",
    "log = []\n",
    "\n",
    "test_dir = '/opt/ml/input/data/train'\n",
    "eval_dir = '/opt/ml/input/data/eval'\n",
    "save_dir = '/opt/ml/image-classification-level1-25/save/'\n",
    "now = (dt.datetime.now().astimezone(timezone(\"Asia/Seoul\")).strftime(\"%Y%m%d_%H%M%S\"))\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = MaskModel(CLASS_NUM)\n",
    "if load_path : model.load_state_dict(torch.load(load_path))    \n",
    "model = model.to(device)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optm = torch.optim.Adam(model.parameters())\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optm, milestones=[6,8,9], gamma=0.1)\n",
    "lrs = []\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "TrainTransform = TrainTrans()\n",
    "TestTransfrom = TestTrans()\n",
    "\n",
    "dataset_train_mask = MaskDataset(test_dir, train='train', transform=TrainTransform)\n",
    "dataset_test_mask = MaskDataset(test_dir, train='test', transform=TestTransfrom)\n",
    "\n",
    "dataloader_train_mask = DataLoader(dataset=dataset_train_mask,\n",
    "                                      batch_size=BATCH_SIZE,\n",
    "                                      num_workers=NUM_WORKERS,\n",
    "                                      )\n",
    "dataloader_test_mask = DataLoader(dataset=dataset_test_mask,\n",
    "                                      batch_size=BATCH_SIZE,\n",
    "                                      num_workers=NUM_WORKERS,\n",
    "                                      )\n",
    "\n",
    "dataloaders = {\n",
    "        \"train\": dataloader_train_mask,\n",
    "        \"test\": dataloader_test_mask\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "log.append(f'{c:#^80}')\n",
    "log.append(f'  [Comment]')\n",
    "log.append(f'{comment}')\n",
    "log.append(f'{c:#^80}')\n",
    "log.append(c); log.append(c); log.append(c)\n",
    "\n",
    "log.append(f'Model         : {model.__class__.__name__}')\n",
    "log.append(f'  load_state  : {load_path}')\n",
    "log.append(f'Dataset       : {dataset_train_mask.__class__.__name__}')\n",
    "log.append(f'  train_len    {len(dataset_train_mask):>10}')\n",
    "log.append(f'  test_len     {len(dataset_test_mask):>10}')\n",
    "log.append(f'Train_trans   : {TrainTrans.__name__}')\n",
    "log.append(f'Test_trans    : {TestTrans.__name__}')\n",
    "log.append(f'Start_Date    : {now}')\n",
    "log.append(f'Device        : {device}')\n",
    "log.append(f'CLASS_NUM     : {CLASS_NUM}')\n",
    "log.append(f'NUM_WORKERS   : {NUM_WORKERS}')\n",
    "log.append(f'BATCH_SIZE    : {BATCH_SIZE}')\n",
    "log.append(f'NUM_EPOCH     : {NUM_EPOCH}')\n",
    "log.append(f'SAVE_INTERVAL : {SAVE_INTERVAL}')\n",
    "\n",
    "\n",
    "for line in log:\n",
    "    print(line)\n",
    "    \n",
    "log.append(c); log.append(c); log.append(c)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "################################################################################\n",
      "  [Comment]\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "Model         : resnetbase3\n",
      "  load_state  : \n",
      "Dataset       : MaskDatasetA\n",
      "  train_len         15120\n",
      "  test_len           3780\n",
      "Train_trans   : A_simple_trans\n",
      "Test_trans    : A_just_tensor\n",
      "Start_Date    : 20210826_211147\n",
      "Device        : cuda:0\n",
      "CLASS_NUM     : 18\n",
      "NUM_WORKERS   : 4\n",
      "BATCH_SIZE    : 16\n",
      "NUM_EPOCH     : 20\n",
      "SAVE_INTERVAL : 3\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# config={\"epochs\": NUM_EPOCH, \"batch_size\": BATCH_SIZE}\n",
    "# wandb.init(project='lv1_p', entity='presto105', config=config)\n",
    "# wandb.run.name = wandb_name"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "best_test_accuracy = 0.\n",
    "best_test_loss = float('inf')\n",
    "best_f1 = 0.\n",
    "\n",
    "for epoch in range(NUM_EPOCH):\n",
    "    for phase in [\"train\", \"test\"]:\n",
    "        running_loss = 0.\n",
    "        running_acc = 0.\n",
    "        running_f1 = 0.\n",
    "        \n",
    "        if phase == \"train\":\n",
    "            model.train()\n",
    "        elif phase == \"test\":\n",
    "            model.eval() \n",
    "            \n",
    "        for idx, (images, labels) in enumerate(pbar := tqdm(dataloaders[phase]), start = 1):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optm.zero_grad()\n",
    "            \n",
    "            with torch.set_grad_enabled(phase == \"train\"):\n",
    "                logits = model(images)\n",
    "                _, preds = torch.max(logits, 1)\n",
    "                loss = loss_fn(logits, labels)\n",
    "                if phase == \"train\":\n",
    "                    loss.backward()  # 모델의 예측 값과 실제 값의 CrossEntropy 차이를 통해 gradient 계산\n",
    "                    optm.step()  # 계산된 gradient를 가지고 모델 업데이트\n",
    "                    lrs.append(optm.param_groups[0][\"lr\"])\n",
    "                    scheduler.step()\n",
    "            \n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            running_acc += torch.sum(preds == labels.data)\n",
    "            running_f1 += f1_loss(labels.data, preds)\n",
    "            pbar.set_description(f\"loss : {running_loss/(idx*BATCH_SIZE):.3f}, acc : {running_acc/(idx*BATCH_SIZE):.3f}, f1 : {running_f1/(idx*BATCH_SIZE):.3f}\")\n",
    "    \n",
    "        epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "        epoch_acc = running_acc / len(dataloaders[phase].dataset)\n",
    "        epoch_f1 = running_f1 / len(dataloaders[phase].dataset)\n",
    "\n",
    "        log.append(f\"[{phase.upper():<5}] Epoch {epoch:0>3d} // (avg) Loss : {epoch_loss:.3f}, Accuracy : {epoch_acc:.3f}, F1 : {epoch_f1:.3f}\")\n",
    "        # wandb.log({'accuracy': epoch_acc, 'loss': epoch_loss, 'F1': epoch_f1})\n",
    "        print(log[-1])\n",
    "        \n",
    "        if phase == \"test\":\n",
    "            if best_test_accuracy < epoch_acc:\n",
    "                best_test_accuracy = epoch_acc\n",
    "            if best_test_loss > epoch_loss:\n",
    "                best_test_loss = epoch_loss\n",
    "            if best_f1 < epoch_f1:\n",
    "                best_f1 = epoch_f1\n",
    "            if epoch % SAVE_INTERVAL == 0:\n",
    "                torch.save(model.state_dict(), os.path.join(save_dir, f'{now}_{model.__class__.__name__}_epoch_{epoch:0>3d}.pt'))\n",
    "\n",
    "torch.save(model.state_dict(), os.path.join(save_dir, f'{now}_{model.__class__.__name__}_finish_{NUM_EPOCH:0>3d}.pt'))\n",
    "\n",
    "\n",
    "log.append(c)\n",
    "print(log[-1])   \n",
    "log.append(c)\n",
    "print(log[-1])  \n",
    "log.append(c)\n",
    "print(log[-1])  \n",
    "log.append(f'{c:#^80}')\n",
    "print(log[-1])            \n",
    "log.append(f':::학습종료:::')\n",
    "print(log[-1])\n",
    "log.append(f\"최고 accuracy : {best_test_accuracy}, 최저 loss : {best_test_loss}, 최고 F1 : {best_f1}\")\n",
    "print(log[-1])\n",
    "log.append(f'{c:#^80}')\n",
    "print(log[-1]) "
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=945.0), HTML(value='')))"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4486ab95aa174214a02383defe97de8d"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-ae9f2c02c0e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 모델의 예측 값과 실제 값의 CrossEntropy 차이를 통해 gradient 계산\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m                     \u001b[0moptm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 계산된 gradient를 가지고 모델 업데이트\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                     \u001b[0;31m# lrs.append(optimizer.param_groups[0][\"lr\"])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, img_paths, transform):\n",
    "        self.img_paths = img_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.img_paths[index])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "\n",
    "# meta 데이터와 이미지 경로를 불러옵니다.\n",
    "submission = pd.read_csv(os.path.join(eval_dir, 'info.csv'))\n",
    "image_dir = os.path.join(eval_dir, 'images')\n",
    "\n",
    "# Test Dataset 클래스 객체를 생성하고 DataLoader를 만듭니다.\n",
    "image_paths = [os.path.join(image_dir, img_id) for img_id in submission.ImageID]\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((512, 384), Image.BILINEAR),\n",
    "    # transforms.CenterCrop(300),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.2, 0.2, 0.2)),\n",
    "])\n",
    "dataset = TestDataset(image_paths, transform)\n",
    "\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# 모델을 정의합니다. (학습한 모델이 있다면 torch.load로 모델을 불러주세요!)\n",
    "device = torch.device('cuda')\n",
    "model.eval()\n",
    "\n",
    "# 모델이 테스트 데이터셋을 예측하고 결과를 저장합니다.\n",
    "all_predictions = []\n",
    "for images in tqdm(loader):\n",
    "    with torch.no_grad():\n",
    "        images = images.to(device)\n",
    "        pred = model(images)\n",
    "        pred = pred.argmax(dim=-1)\n",
    "        all_predictions.extend(pred.cpu().numpy())\n",
    "submission['ans'] = all_predictions"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=12600.0), HTML(value='')))"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9da66976e8874952b9d546e1545dc465"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "# 제출할 파일을 저장합니다.\n",
    "submission.to_csv(os.path.join(save_dir, f'{now}_result.csv'), index=False)\n",
    "log.append(f'test inference is done!')\n",
    "print(log[-1])\n",
    "log.append(c)\n",
    "print(log[-1])\n",
    "log.append(f'{c:-^80}')\n",
    "print(log[-1])\n",
    "log.append(c)\n",
    "print(log[-1])\n",
    "\n",
    "\n",
    "\n",
    "# log 저장\n",
    "with open(os.path.join(save_dir, f'{now}.log'), \"w\") as f:\n",
    "    now = (dt.datetime.now().astimezone(timezone(\"Asia/Seoul\")).strftime(\"%Y%m%d_%H%M%S\"))\n",
    "    log.append(f'Finish_Date    : {now}')\n",
    "    print(log[-1])\n",
    "    for line in log: \n",
    "        f.write(line+'\\n')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "test inference is done!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Finish_Date    : 20210826_210245\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}