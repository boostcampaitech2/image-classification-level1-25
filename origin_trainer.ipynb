{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from pytz import timezone\n",
    "import datetime as dt\n",
    "\n",
    "from f1_score import f1_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.model_kj import resnetbase as MaskModel\n",
    "from datasets.dataset_kj import MaskDatasetA as MaskDataset\n",
    "from trans.trans_kj import A_simple_trans as TrainTrans\n",
    "from trans.trans_kj import A_just_tensor as TestTrans\n",
    "\n",
    "CLASS_NUM = 18\n",
    "NUM_WORKERS = 4\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCH = 3\n",
    "SAVE_INTERVAL = 3\n",
    "\n",
    "load_path = ''\n",
    "\n",
    "comment = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = ''\n",
    "log = []\n",
    "\n",
    "test_dir = '/opt/ml/input/data/train'\n",
    "eval_dir = '/opt/ml/input/data/eval'\n",
    "save_dir = '/opt/ml/image-classification-level1-25/save/'\n",
    "now = (dt.datetime.now().astimezone(timezone(\"Asia/Seoul\")).strftime(\"%Y%m%d_%H%M%S\"))\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = MaskModel(CLASS_NUM)\n",
    "if load_path : model.load_state_dict(torch.load(load_path))    \n",
    "model = model.to(device)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optm = torch.optim.Adam(model.parameters())\n",
    "\n",
    "TrainTransform = TrainTrans()\n",
    "TestTransfrom = TestTrans()\n",
    "\n",
    "dataset_train_mask = MaskDataset(test_dir, train='train', transform=TrainTransform)\n",
    "dataset_test_mask = MaskDataset(test_dir, train='test', transform=TestTransfrom)\n",
    "\n",
    "dataloader_train_mask = DataLoader(dataset=dataset_train_mask,\n",
    "                                      batch_size=BATCH_SIZE,\n",
    "                                      num_workers=NUM_WORKERS,\n",
    "                                      )\n",
    "dataloader_test_mask = DataLoader(dataset=dataset_test_mask,\n",
    "                                      batch_size=BATCH_SIZE,\n",
    "                                      num_workers=NUM_WORKERS,\n",
    "                                      )\n",
    "\n",
    "dataloaders = {\n",
    "        \"train\": dataloader_train_mask,\n",
    "        \"test\": dataloader_test_mask\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################################################\n",
      "  [Comment]\n",
      "comment test\n",
      " hahaha\n",
      "haha\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "Model         : resnetbase\n",
      "  load_state  : /opt/ml/image-classification-level1-25/save/albu resnet/20210826_031737_resnetbase_epoch_024.pt\n",
      "Dataset       : MaskDatasetA\n",
      "  train_len         15120\n",
      "  test_len           3780\n",
      "Train_trans   : A_random_trans\n",
      "Test_trans    : A_just_tensor\n",
      "Start_Date    : 20210826_102628\n",
      "Device        : cuda:0\n",
      "CLASS_NUM     : 18\n",
      "NUM_WORKERS   : 4\n",
      "BATCH_SIZE    : 32\n",
      "NUM_EPOCH     : 3\n",
      "SAVE_INTERVAL : 3\n"
     ]
    }
   ],
   "source": [
    "log.append(f'{c:#^80}')\n",
    "log.append(f'  [Comment]')\n",
    "log.append(f'{comment}')\n",
    "log.append(f'{c:#^80}')\n",
    "log.append(c); log.append(c); log.append(c)\n",
    "\n",
    "log.append(f'Model         : {model.__class__.__name__}')\n",
    "log.append(f'  load_state  : {load_path}')\n",
    "log.append(f'Dataset       : {dataset_train_mask.__class__.__name__}')\n",
    "log.append(f'  train_len    {len(dataset_train_mask):>10}')\n",
    "log.append(f'  test_len     {len(dataset_test_mask):>10}')\n",
    "log.append(f'Train_trans   : {TrainTrans.__name__}')\n",
    "log.append(f'Test_trans    : {TestTrans.__name__}')\n",
    "log.append(f'Start_Date    : {now}')\n",
    "log.append(f'Device        : {device}')\n",
    "log.append(f'CLASS_NUM     : {CLASS_NUM}')\n",
    "log.append(f'NUM_WORKERS   : {NUM_WORKERS}')\n",
    "log.append(f'BATCH_SIZE    : {BATCH_SIZE}')\n",
    "log.append(f'NUM_EPOCH     : {NUM_EPOCH}')\n",
    "log.append(f'SAVE_INTERVAL : {SAVE_INTERVAL}')\n",
    "\n",
    "\n",
    "for line in log:\n",
    "    print(line)\n",
    "    \n",
    "log.append(c); log.append(c); log.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9f3c93b385944dda34dd879ba88987b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=473.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[TRAIN] Epoch 000 // (avg) Loss : 0.279, Accuracy : 0.899, F1 : 0.290\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ec709767f954a3a962b0d5e6a6d0351",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=119.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[TEST ] Epoch 000 // (avg) Loss : 1.080, Accuracy : 0.629, F1 : 0.269\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80a643c83c274aca8ad6cf97de821508",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=473.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[TRAIN] Epoch 001 // (avg) Loss : 0.253, Accuracy : 0.909, F1 : 0.290\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c8e973cc47346539093f6ad24526741",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=119.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[TEST ] Epoch 001 // (avg) Loss : 0.914, Accuracy : 0.740, F1 : 0.295\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae17ea3fef3a4df4b18bfe521e86462c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=473.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[TRAIN] Epoch 002 // (avg) Loss : 0.263, Accuracy : 0.903, F1 : 0.290\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90620a0e2f7846e0a5a9127fb86e97b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=119.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[TEST ] Epoch 002 // (avg) Loss : 0.855, Accuracy : 0.744, F1 : 0.293\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      ":::학습종료:::\n",
      "최고 accuracy : 0.744179904460907, 최저 loss : 0.8548999578233749, 최고 F1 : 0.2946680188179016\n",
      "################################################################################\n"
     ]
    }
   ],
   "source": [
    "# SAMPLE 복붙\n",
    "best_test_accuracy = 0.\n",
    "best_test_loss = float('inf')\n",
    "best_f1 = 0.\n",
    "\n",
    "for epoch in range(NUM_EPOCH):\n",
    "    for phase in [\"train\", \"test\"]:\n",
    "        running_loss = 0.\n",
    "        running_acc = 0.\n",
    "        running_f1 = 0.\n",
    "        \n",
    "        if phase == \"train\":\n",
    "            model.train()\n",
    "        elif phase == \"test\":\n",
    "            model.eval() \n",
    "            \n",
    "        for idx, (images, labels) in enumerate(pbar := tqdm(dataloaders[phase]), start = 1):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optm.zero_grad()\n",
    "            \n",
    "            with torch.set_grad_enabled(phase == \"train\"):\n",
    "                logits = model(images)\n",
    "                _, preds = torch.max(logits, 1)\n",
    "                loss = loss_fn(logits, labels)\n",
    "                if phase == \"train\":\n",
    "                    loss.backward()  # 모델의 예측 값과 실제 값의 CrossEntropy 차이를 통해 gradient 계산\n",
    "                    optm.step()  # 계산된 gradient를 가지고 모델 업데이트\n",
    "            \n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            running_acc += torch.sum(preds == labels.data)\n",
    "            running_f1 += f1_loss(labels.data, preds)\n",
    "            pbar.set_description(f\"loss : {running_loss/(idx*BATCH_SIZE):.3f}, acc : {running_acc/(idx*BATCH_SIZE):.3f}, f1 : {running_f1/(idx*BATCH_SIZE):.3f}\")\n",
    "    \n",
    "        epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "        epoch_acc = running_acc / len(dataloaders[phase].dataset)\n",
    "        epoch_f1 = running_f1 / len(dataloaders[phase].dataset)\n",
    "\n",
    "        log.append(f\"[{phase.upper():<5}] Epoch {epoch:0>3d} // (avg) Loss : {epoch_loss:.3f}, Accuracy : {epoch_acc:.3f}, F1 : {epoch_f1:.3f}\")\n",
    "        print(log[-1])\n",
    "        \n",
    "        if phase == \"test\":\n",
    "            if best_test_accuracy < epoch_acc:\n",
    "                best_test_accuracy = epoch_acc\n",
    "            if best_test_loss > epoch_loss:\n",
    "                best_test_loss = epoch_loss\n",
    "            if best_f1 < epoch_f1:\n",
    "                best_f1 = epoch_f1\n",
    "            if epoch % SAVE_INTERVAL == 0:\n",
    "                torch.save(model.state_dict(), os.path.join(save_dir, f'{now}_{model.__class__.__name__}_epoch_{epoch:0>3d}.pt'))\n",
    "\n",
    "torch.save(model.state_dict(), os.path.join(save_dir, f'{now}_{model.__class__.__name__}_finish_{NUM_EPOCH:0>3d}.pt'))\n",
    "\n",
    "\n",
    "log.append(c)\n",
    "print(log[-1])   \n",
    "log.append(c)\n",
    "print(log[-1])  \n",
    "log.append(c)\n",
    "print(log[-1])  \n",
    "log.append(f'{c:#^80}')\n",
    "print(log[-1])            \n",
    "log.append(f':::학습종료:::')\n",
    "print(log[-1])\n",
    "log.append(f\"최고 accuracy : {best_test_accuracy}, 최저 loss : {best_test_loss}, 최고 F1 : {best_f1}\")\n",
    "print(log[-1])\n",
    "log.append(f'{c:#^80}')\n",
    "print(log[-1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66f069ae6d334320b604e03cb64657f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=12600.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, img_paths, transform):\n",
    "        self.img_paths = img_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.img_paths[index])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "\n",
    "# meta 데이터와 이미지 경로를 불러옵니다.\n",
    "submission = pd.read_csv(os.path.join(eval_dir, 'info.csv'))\n",
    "image_dir = os.path.join(eval_dir, 'images')\n",
    "\n",
    "# Test Dataset 클래스 객체를 생성하고 DataLoader를 만듭니다.\n",
    "image_paths = [os.path.join(image_dir, img_id) for img_id in submission.ImageID]\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((512, 384), Image.BILINEAR),\n",
    "    # transforms.CenterCrop(300),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.2, 0.2, 0.2)),\n",
    "])\n",
    "dataset = TestDataset(image_paths, transform)\n",
    "\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# 모델을 정의합니다. (학습한 모델이 있다면 torch.load로 모델을 불러주세요!)\n",
    "device = torch.device('cuda')\n",
    "model.eval()\n",
    "\n",
    "# 모델이 테스트 데이터셋을 예측하고 결과를 저장합니다.\n",
    "all_predictions = []\n",
    "for images in tqdm(loader):\n",
    "    with torch.no_grad():\n",
    "        images = images.to(device)\n",
    "        pred = model(images)\n",
    "        pred = pred.argmax(dim=-1)\n",
    "        all_predictions.extend(pred.cpu().numpy())\n",
    "submission['ans'] = all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test inference is done!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Finish_Date    : 20210826_102851\n"
     ]
    }
   ],
   "source": [
    "# 제출할 파일을 저장합니다.\n",
    "submission.to_csv(os.path.join(save_dir, f'{now}_result.csv'), index=False)\n",
    "log.append(f'test inference is done!')\n",
    "print(log[-1])\n",
    "log.append(c)\n",
    "print(log[-1])\n",
    "log.append(f'{c:-^80}')\n",
    "print(log[-1])\n",
    "log.append(c)\n",
    "print(log[-1])\n",
    "\n",
    "\n",
    "\n",
    "# log 저장\n",
    "with open(os.path.join(save_dir, f'{now}.log'), \"w\") as f:\n",
    "    now = (dt.datetime.now().astimezone(timezone(\"Asia/Seoul\")).strftime(\"%Y%m%d_%H%M%S\"))\n",
    "    log.append(f'Finish_Date    : {now}')\n",
    "    print(log[-1])\n",
    "    for line in log: \n",
    "        f.write(line+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}