{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from pytz import timezone\n",
    "import datetime as dt\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from module.f1_Loss import F1_Loss"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from models.model_kj import resnetbase as MaskModel\n",
    "from datasets.dataset_kj import basicDatasetA as MaskDataset\n",
    "from trans.trans_kj import A_random_trans_no_cut as TrainTrans\n",
    "from trans.trans_kj import A_just_tensor as TestTrans\n",
    "\n",
    "CLASS_NUM = 18\n",
    "NUM_WORKERS = 4\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCH = 30\n",
    "SAVE_INTERVAL = 2\n",
    "\n",
    "load_path = ''\n",
    "\n",
    "comment = ''"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "c = ''\n",
    "log = []\n",
    "\n",
    "test_dir = '/opt/ml/input/data/train'\n",
    "eval_dir = '/opt/ml/input/data/eval'\n",
    "save_dir = '/opt/ml/image-classification-level1-25/save/'\n",
    "now = (dt.datetime.now().astimezone(timezone(\"Asia/Seoul\")).strftime(\"%Y%m%d_%H%M%S\"))\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = MaskModel(CLASS_NUM)\n",
    "if load_path : model.load_state_dict(torch.load(load_path))    \n",
    "model = model.to(device)\n",
    "\n",
    "# loss_fn = torch.nn.CrossEntropyLoss()\n",
    "loss_fn = F1_Loss(classes=CLASS_NUM)\n",
    "optm = torch.optim.Adam(model.parameters())\n",
    "\n",
    "TrainTransform = TrainTrans()\n",
    "TestTransfrom = TestTrans()\n",
    "\n",
    "dataset_train_mask = MaskDataset(test_dir, mode='train', transform=TrainTransform)\n",
    "dataset_test_mask = MaskDataset(test_dir, mode='test', transform=TestTransfrom)\n",
    "\n",
    "dataloader_train_mask = DataLoader(dataset=dataset_train_mask,\n",
    "                                      batch_size=BATCH_SIZE,\n",
    "                                      num_workers=NUM_WORKERS,\n",
    "                                      )\n",
    "dataloader_test_mask = DataLoader(dataset=dataset_test_mask,\n",
    "                                      batch_size=BATCH_SIZE,\n",
    "                                      num_workers=NUM_WORKERS,\n",
    "                                      )\n",
    "\n",
    "dataloaders = {\n",
    "        \"train\": dataloader_train_mask,\n",
    "        \"test\": dataloader_test_mask\n",
    "    }"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "log.append(f'{c:#^80}')\n",
    "log.append(f'  [Comment]')\n",
    "log.append(f'{comment}')\n",
    "log.append(f'{c:#^80}')\n",
    "log.append(c); log.append(c); log.append(c)\n",
    "\n",
    "log.append(f'Model         : {model.__class__.__name__}')\n",
    "log.append(f'  load_state  : {load_path}')\n",
    "log.append(f'Dataset       : {dataset_train_mask.__class__.__name__}')\n",
    "log.append(f'  train_len    {len(dataset_train_mask):>10}')\n",
    "log.append(f'  test_len     {len(dataset_test_mask):>10}')\n",
    "log.append(f'Train_trans   : {TrainTrans.__name__}')\n",
    "log.append(f'Test_trans    : {TestTrans.__name__}')\n",
    "log.append(f'Start_Date    : {now}')\n",
    "log.append(f'Device        : {device}')\n",
    "log.append(f'CLASS_NUM     : {CLASS_NUM}')\n",
    "log.append(f'NUM_WORKERS   : {NUM_WORKERS}')\n",
    "log.append(f'BATCH_SIZE    : {BATCH_SIZE}')\n",
    "log.append(f'NUM_EPOCH     : {NUM_EPOCH}')\n",
    "log.append(f'SAVE_INTERVAL : {SAVE_INTERVAL}')\n",
    "\n",
    "\n",
    "for line in log:\n",
    "    print(line)\n",
    "    \n",
    "log.append(c); log.append(c); log.append(c)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "################################################################################\n",
      "  [Comment]\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "Model         : resnetbase\n",
      "  load_state  : \n",
      "Dataset       : basicDatasetA\n",
      "  train_len         17010\n",
      "  test_len           1890\n",
      "Train_trans   : A_random_trans_no_cut\n",
      "Test_trans    : A_just_tensor\n",
      "Start_Date    : 20210830_102706\n",
      "Device        : cuda:0\n",
      "CLASS_NUM     : 18\n",
      "NUM_WORKERS   : 2\n",
      "BATCH_SIZE    : 128\n",
      "NUM_EPOCH     : 30\n",
      "SAVE_INTERVAL : 2\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# SAMPLE 복붙\n",
    "best_test_accuracy = 0.\n",
    "best_test_loss = float('inf')\n",
    "best_f1 = 0.\n",
    "\n",
    "for epoch in range(NUM_EPOCH):\n",
    "    # for phase in [\"test\"]:\n",
    "    for phase in [\"train\", \"test\"]:\n",
    "        running_loss = 0.\n",
    "        running_acc = 0.\n",
    "        running_f1 = 0.\n",
    "        \n",
    "        if phase == \"train\":\n",
    "            model.train()\n",
    "        elif phase == \"test\":\n",
    "            model.eval() \n",
    "            \n",
    "        for idx, (images, labels) in enumerate(pbar := tqdm(dataloaders[phase]), start = 1):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optm.zero_grad()\n",
    "            \n",
    "            with torch.set_grad_enabled(phase == \"train\"):\n",
    "                logits = model(images)\n",
    "                _, preds = torch.max(logits, 1)\n",
    "                loss = loss_fn(logits, labels)\n",
    "                if phase == \"train\":\n",
    "                    loss.backward()  # 모델의 예측 값과 실제 값의 CrossEntropy 차이를 통해 gradient 계산\n",
    "                    optm.step()  # 계산된 gradient를 가지고 모델 업데이트\n",
    "            \n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            running_acc += torch.sum(preds == labels.data)\n",
    "            running_f1 += f1_score(labels.data.cpu().numpy(), preds.cpu().numpy(), average='macro')\n",
    "            pbar.set_description(f\"loss : {running_loss/(idx*BATCH_SIZE):.3f}, acc : {running_acc/(idx*BATCH_SIZE):.3f}, Macro_f1 : {running_f1/(idx):.3f}\")\n",
    "    \n",
    "        epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "        epoch_acc = running_acc / len(dataloaders[phase].dataset)\n",
    "        epoch_f1 = running_f1 / len(dataloaders[phase])\n",
    "\n",
    "        log.append(f\"[{phase.upper():<5}] Epoch {epoch:0>3d} // (avg) Loss : {epoch_loss:.3f}, Accuracy : {epoch_acc:.3f}, Macro_f1 : {epoch_f1:.5f}\")\n",
    "        print(log[-1])\n",
    "        \n",
    "        if phase == \"test\":\n",
    "            if best_test_accuracy < epoch_acc:\n",
    "                best_test_accuracy = epoch_acc\n",
    "            if best_test_loss > epoch_loss:\n",
    "                best_test_loss = epoch_loss\n",
    "            if best_f1 < epoch_f1:\n",
    "                best_f1 = epoch_f1\n",
    "            if epoch % SAVE_INTERVAL == 0:\n",
    "                torch.save(model.state_dict(), os.path.join(save_dir, f'{now}_{model.__class__.__name__}_epoch_{epoch:0>3d}.pt'))\n",
    "\n",
    "torch.save(model.state_dict(), os.path.join(save_dir, f'{now}_{model.__class__.__name__}_finish_{NUM_EPOCH:0>3d}.pt'))\n",
    "\n",
    "\n",
    "log.append(c)\n",
    "print(log[-1])   \n",
    "log.append(c)\n",
    "print(log[-1])  \n",
    "log.append(c)\n",
    "print(log[-1])  \n",
    "log.append(f'{c:#^80}')\n",
    "print(log[-1])            \n",
    "log.append(f':::학습종료:::')\n",
    "print(log[-1])\n",
    "log.append(f\"최고 accuracy : {best_test_accuracy:.5f}, 최저 loss : {best_test_loss:.5f}, 최고 Macro_F1 : {best_f1:.5f}\")\n",
    "print(log[-1])\n",
    "log.append(f'{c:#^80}')\n",
    "print(log[-1]) "
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=133.0), HTML(value='')))"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7685966e7353417faad059bd56442bd8"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-cdd33a0ffd2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 모델의 예측 값과 실제 값의 CrossEntropy 차이를 통해 gradient 계산\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/image-classification-level1-25/module/f1_Loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, y_pred, y_true)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, img_paths, transform):\n",
    "        self.img_paths = img_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.img_paths[index])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image=np.array(image))['image'].float()\n",
    "        return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "\n",
    "# meta 데이터와 이미지 경로를 불러옵니다.\n",
    "submission = pd.read_csv(os.path.join(eval_dir, 'info.csv'))\n",
    "image_dir = os.path.join(eval_dir, 'images')\n",
    "\n",
    "# Test Dataset 클래스 객체를 생성하고 DataLoader를 만듭니다.\n",
    "image_paths = [os.path.join(image_dir, img_id) for img_id in submission.ImageID]\n",
    "dataset = TestDataset(image_paths, TestTransfrom)\n",
    "\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# 모델을 정의합니다. (학습한 모델이 있다면 torch.load로 모델을 불러주세요!)\n",
    "device = torch.device('cuda')\n",
    "model.eval()\n",
    "\n",
    "# 모델이 테스트 데이터셋을 예측하고 결과를 저장합니다.\n",
    "all_predictions = []\n",
    "for images in tqdm(loader):\n",
    "    with torch.no_grad():\n",
    "        images = images.to(device)\n",
    "        pred = model(images)\n",
    "        pred = pred.argmax(dim=-1)\n",
    "        all_predictions.extend(pred.cpu().numpy())\n",
    "submission['ans'] = all_predictions"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=12600.0), HTML(value='')))"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6e4e687ae133443d9325c35aeefaac1f"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# 제출할 파일을 저장합니다.\n",
    "submission.to_csv(os.path.join(save_dir, f'{now}_result.csv'), index=False)\n",
    "log.append(f'test inference is done!')\n",
    "print(log[-1])\n",
    "log.append(c)\n",
    "print(log[-1])\n",
    "log.append(f'{c:-^80}')\n",
    "print(log[-1])\n",
    "log.append(c)\n",
    "print(log[-1])\n",
    "\n",
    "\n",
    "\n",
    "# log 저장\n",
    "with open(os.path.join(save_dir, f'{now}.log'), \"w\") as f:\n",
    "    now = (dt.datetime.now().astimezone(timezone(\"Asia/Seoul\")).strftime(\"%Y%m%d_%H%M%S\"))\n",
    "    log.append(f'Finish_Date    : {now}')\n",
    "    print(log[-1])\n",
    "    for line in log: \n",
    "        f.write(line+'\\n')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "test inference is done!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Finish_Date    : 20210827_171235\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}